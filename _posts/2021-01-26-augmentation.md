---
layout: post
title: Overview
---

Like many, my journey into creative coding was guided by Daniel Shiffman’s Nature of Code. When it first came out in 2012, it was one of the few resources which explained the core concepts of coding in an easy to understand manner. At the end of a chapter, Daniel urged the reader to implement the concepts by creating a ‘pond’, an ecosystem with intelligent agents which would act of their own accord, and employ a genetic system, much like real life. I never got around to actually creating this ecosystem, partly because it was a difficult undertaking. 

![pond-proto](/pond/media/pond-proto.png)

I tried to create a few variations, but never managed to figure out how to create intelligent agents capable of interacting with each other. My interest in creating an artificial ecosystem didn’t fade, and I finally decided to create one, but with a unique tweak. Most Artificial Life (AL) systems replicated reality, or at the very least, followed the same rules of predation, and natural selection. I wanted to explore alternative metrics of natural selection. Would being nice to each other help the species as a whole thrive? Or is the idea of the selfish gene far too efficient? My intent with the AL system was to create an homeostatic system which would then be induced with behaviours such as sharing, community, and respect for the environment, with the hopes of comparing the tweaked systems with the baseline to observe if there were any changes, if at all.


## Iteration 1

I took an iterative approach toward creating the AL ecosystem, adding features and behaviours to the system layer by layer. The first iteration consisted of two types of entities, an agent (square) and a food particle (circle. The food particles are randomly distributed across the canvas, with the agents moving around the space hunting for food with the help of a simple physics engine. Each agent had a hunger threshold, and would lose hunger every second. In order to regain their hunger, they would need to eat food. The agents use a simple vector based targeting system to lock on to the position of the nearest food particle in order to locomote towards it. The colour of the agent would change depending on how much hunger they had remaining. The scenario would start with all agents having low hunger, denoted by them being coloured black, and once they eat food and cross a certain hunger threshold, their colour would switch to white. The system worked well, with the agents chasing after all the food particles in the space, and the colour system denoted their hunger. However, at this stage, the agents didn’t have any intelligence of their own. They were simply programmed to look for food, and change colour when their individual hunger crossed a certain threshold. They could do nothing else.